{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdf2image\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_DIRECTORY = \"..\\data\"\n",
    "OUTPUT_DIRECTORY = \".\\output\"\n",
    "EXTRACTED_TEXT_DIRECTORY = \"./output/text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import fitz \n",
    "import camelot\n",
    "import pdf2image\n",
    "import io\n",
    "\n",
    "\n",
    "def capture_images_from_pdf(pdf_directory):\n",
    "    images = pdf2image.convert_from_path(pdf_path=pdf_directory)\n",
    "    return images\n",
    "\n",
    "def extract_images_from_page(image_path):\n",
    "   \n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, threshold1=50, threshold2=150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    extracted_images = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > 50 and h > 50:\n",
    "            cropped_img = img[y:y+h, x:x+w]\n",
    "            _, img_encoded = cv2.imencode('.jpg', cropped_img)\n",
    "            img_bytes = img_encoded.tobytes()\n",
    "            extracted_images.append((x, y, w, h, img_bytes))\n",
    "    return extracted_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def text_extractor(image_path):\n",
    "   \n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image, lang='eng')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "def describe_image(image_path):\n",
    "    \"\"\"\n",
    "    Generate a textual description of an image using a pre-trained image captioning model.\n",
    "\n",
    "    :param image_path: Path to the image file.\n",
    "    :return: A textual description of the image.\n",
    "    \"\"\"\n",
    "    # Load the pre-trained model and processor\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "    # Load and process the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate caption\n",
    "    out = model.generate(**inputs)\n",
    "    description = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    return description\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\SURYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SURYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SURYA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Download NLTK data (if not already installed)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess the text by removing stop words, punctuation, and applying stemming.\n",
    "    \n",
    "    :param text: Raw text to be processed.\n",
    "    :return: Cleaned and preprocessed text.\n",
    "    \"\"\"\n",
    "    # Initialize the stop words and stemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Convert to lowercase and remove punctuation\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "    # Remove stop words and apply stemming\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "\n",
    "    # Reassemble the text\n",
    "    clean_text = ' '.join(words)\n",
    "\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_image(image_path):\n",
    " \n",
    "    text = text_extractor(image_path)\n",
    "    extracted_images = extract_images_from_page(image_path)\n",
    "    \n",
    "    \n",
    "    combined_text = preprocess_text(text)\n",
    "    for (x, y, w, h, img_bytes) in extracted_images:\n",
    "        img_text = pytesseract.image_to_string(Image.open(io.BytesIO(img_bytes)), lang='eng')\n",
    "        img_description = describe_image(io.BytesIO(img_bytes))\n",
    "        combined_text += f\"\\n\\n[Image at ({x},{y}) with size ({w}x{h})]: {img_text}\\nDescription: {img_description}\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "\n",
    "\n",
    "def save_text_to_file(book , pgno,chunkno , text):\n",
    "    file_name = f\"{book}_{pgno}_{chunkno}.txt\"\n",
    "    file_path = os.path.join(OUTPUT_DIRECTORY, \"text\", file_name)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "def process_book_page(book_path, book_name, page_num, chunk_number):\n",
    "    image_path = f\"temp_image_{chunk_number}_{page_num}.jpg\"\n",
    "    images_from_book = capture_images_from_pdf(book_path)\n",
    "    image = images_from_book[page_num]\n",
    "    image.save(image_path, 'JPEG')\n",
    "    \n",
    "    combined_text = extract_data_from_image(image_path)\n",
    "    save_text_to_file(book_name, page_num + 1, chunk_number, combined_text)\n",
    "    os.remove(image_path)\n",
    "\n",
    "\n",
    "def extract_data_from_directory(data_directory):\n",
    "    data_root_directory = data_directory\n",
    "    books_directory = os.listdir(data_root_directory)\n",
    "    chunk_number = 1\n",
    "    for book in books_directory:\n",
    "        book_path = os.path.join(data_directory, book)\n",
    "        if os.path.isfile(book_path) and book_path.endswith(\".pdf\"):\n",
    "            images_from_book = capture_images_from_pdf(book_path)\n",
    "            for page_num, image in enumerate(images_from_book):\n",
    "\n",
    "                image_path = f\"temp_image_{chunk_number}_{page_num}.jpg\"\n",
    "                image.save(image_path, 'JPEG')\n",
    "                combined_text = extract_data_from_image(image_path)\n",
    "                save_text_to_file(os.path.splitext(book)[0], page_num + 1, chunk_number, combined_text)\n",
    "                chunk_number+=1\n",
    "                os.remove(image_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data_from_directory(DATA_FOLDER_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
